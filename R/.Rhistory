# Verificar que la lista tiene el número esperado de data frames
print(paste("Número de data frames en datalist:", length(datalist)))
# Cargar todos los archivos en una lista
datalist <- lapply(file_paths, read.delim, sep = ",", dec = ".")
# Verificar que la lista tiene el número esperado de data frames
print(paste("Número de data frames en datalist:", length(datalist)))
# Verificar cuántos archivos se han encontrado
print(paste("Número de archivos encontrados:", length(file_paths)))
# Leer los archivos en una lista de data frames
file_paths <- list.files("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/",
pattern = "lswi_zone.*\\.csv$", full.names = TRUE)
# Verificar cuántos archivos se han encontrado
print(paste("Número de archivos encontrados:", length(file_paths)))
# Cargar todos los archivos en una lista
datalist <- lapply(file_paths, read.delim, sep = ",", dec = ".")
# Verificar que la lista tiene el número esperado de data frames
print(paste("Número de data frames en datalist:", length(datalist)))
# Listar todos los archivos CSV en el directorio
file_paths <- list.files("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/",
pattern = "\\.csv$", full.names = TRUE)
print(file_paths)
# Verificar cuántos archivos se han encontrado
print(paste("Número de archivos encontrados:", length(file_paths)))
?list.files
# Listar todos los archivos CSV en el directorio
file_paths <- list.files("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/",
pattern = "\\.csv", full.names = TRUE)
print(file_paths)
datalist<-list(data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone01b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone02b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone03b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone04b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone05b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone06b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone07b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone08b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone09b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone10b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone11b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone12b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone13b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone14b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone15b.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone01.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone02.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone03.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone04.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone05.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone06.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone07.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone08.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone09.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone10.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone11.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone12.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone13.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone14.csv", sep=",", dec = "."),
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone15.csv", sep=",", dec = "."))
for (i in 1:30) {
datalist[i]
nt_test <- notrend_test(datalist$LSWI)
mk_test <- notrend_test(datalist$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ datalist$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(datalist$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
for (i in 1:30) {
datalist[i]
nt_test <- notrend_test(datalist[i]$LSWI)
mk_test <- notrend_test(datalist[i]$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ datalist[i]$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(datalist[i]$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
for (i in 1:30) {
data<-datalist[i]
nt_test <- notrend_test(datos$LSWI)
mk_test <- notrend_test(datos$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ datos$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(datos$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
# Intentar listar todos los archivos CSV en el directorio
file_paths <- list.files("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/",
pattern = "\\.csv$", full.names = TRUE)
# Mostrar los archivos encontrados
print(paste("Archivos encontrados:", file_paths))
# Si se encontraron archivos, proceder a leerlos
if (length(file_paths) > 0) {
datalist <- lapply(file_paths, read.delim, sep = ",", dec = ".")
print(paste("Número de data frames en datalist:", length(datalist)))
# Ahora continúa con tu bucle para realizar los análisis...
} else {
print("No se encontraron archivos CSV en la ruta especificada.")
}
datalist<-list(read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone01b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone02b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone03b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone04b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone05b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone06b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone07b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone08b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone09b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone10b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone11b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone12b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone13b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone14b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone15b.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone01.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone02.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone03.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone04.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone05.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone06.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone07.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone08.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone09.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone10.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone11.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone12.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone13.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone14.csv", sep=",", dec = "."),
read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_humedal/lswi_zone15.csv", sep=",", dec = "."))
for (i in 1:30) {
data<-datalist[i]
nt_test <- notrend_test(datos$LSWI)
mk_test <- notrend_test(datos$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ datos$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(datos$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
for (i in 1:30) {
data<-datalist[i]
nt_test <- notrend_test(data$LSWI)
mk_test <- notrend_test(data$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ data$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(data$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
for (i in 1:30) {
data<-datalist[i]
data
nt_test <- notrend_test(data$LSWI)
mk_test <- notrend_test(data$LSWI, test='MK')
lm_model <- lm(data$LSWI ~ data$Year)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(data$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
}
# Inicializar las variables que almacenarán los resultados
n <- 30  # Número de archivos que esperas procesar
for (i in 1:length(datalist)) {
data <- datalist[[i]]
# Asegurarte de que LSWI es numérico y un vector
data$LSWI <- as.numeric(as.character(data$LSWI))
if (any(is.na(data$LSWI))) {
data <- na.omit(data)
}
# Realizar los análisis
if (is.vector(data$LSWI) && !is.matrix(data$LSWI)) {
nt_test <- notrend_test(data$LSWI)
mk_test <- notrend_test(data$LSWI, test='MK')
lm_model <- lm(LSWI ~ Year, data = data)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(data$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary
a
a
?
)
)
for (i in 1:length(datalist)) {
data <- datalist[[i]]
# Asegurarte de que LSWI es numérico y un vector
data$LSWI <- as.numeric(as.character(data$LSWI))
if (any(is.na(data$LSWI))) {
data <- na.omit(data)
}
# Realizar los análisis
if (is.vector(data$LSWI) && !is.matrix(data$LSWI)) {
nt_test <- notrend_test(data$LSWI)
mk_test <- notrend_test(data$LSWI, test='MK')
lm_model <- lm(LSWI ~ Year, data = data)
summary_lm <- summary(lm_model)
mk_test_2 <- MannKendall(data$LSWI)
intercept_lm[i] <- summary_lm$coefficients[1, "Estimate"]
slope_lm[i] <- summary_lm$coefficients[2, "Estimate"]
p_value_slope[i] <- summary_lm$coefficients[2, "Pr(>|t|)"]
r_squared[i] <- summary_lm$r.squared
adj_r_squared[i] <- summary_lm$adj.r.squared
tau_mk_test_2[i] <- mk_test_2$tau
p_value_mk_test_2[i] <- mk_test_2$sl
} else {
print(paste("Error en la iteración", i, ": LSWI no es un vector univariado."))
}
}
# Verificar los resultados
results_df <- data.frame(
intercept_lm,
slope_lm,
p_value_slope,
r_squared,
adj_r_squared,
tau_mk_test_2,
p_value_mk_test_2
)
print(results_df)
summary_lm
View(results_df)
?format
a<-6.278387e-01
format(a, nsmall = 3)
format(results_df, nsmall = 3)
format(results_df, nsmall = 5)
format(results_df, scientific = 4)
format(results_df, scientific = 3)
format(results_df, scientific = 10)
format(results_df, scientific = 6)
format(results_df, scientific = 4)
format(results_df, scientific = 5)
print(results_df)
format(results_df, scientific = 5)
results_dff<-format(results_df, scientific = 5)
results_dff
results_df <- format(results_df, scientific = 5)
print(results_df)
t(results_df)
View(t(results_df))
View(results_df)
c(paste(rep(zone),1:15,"b")))
c(paste(rep(zone),1:15,"b"))
c(paste(rep("zone",15),1:15,"b"))
?paste
c(paste(rep("zone",15),1:15,"b"), sep="")
c(paste(rep("zone",15),1:15,"b",sep = ""))
c(paste(rep("zone",15),sprintf("%02d", 15),"b",sep = ""))
c(paste(rep("zone",15),sprintf("%02d", 1:15),"b",sep = ""))
c(paste(rep("zone",15),sprintf("%02d", 1:15),"b",sep = ""))+c(1:5)
c(c(paste(rep("zone",15),sprintf("%02d", 1:15),"b",sep = "")),1:5)
c(c(paste(rep("zone",15),sprintf("%02d", 1:15),"b",sep = "")),c(paste(rep("zone",15),sprintf("%02d", 1:15),sep = "")))
?rownames
rownames(results_df)<-c(c(paste(rep("zone",15),sprintf("%02d", 1:15),"b",sep = "")),c(paste(rep("zone",15),sprintf("%02d", 1:15),sep = "")))
rownames(results_df)
View(results_df)
#Option A #library(funtimes)
notrend_test(data$LSWI)
# Data
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone01b.csv", sep=",", dec = ".")
#Option A #library(funtimes)
notrend_test(data$LSWI)
notrend_test(data$LSWI,test='MK') # Usa esta función
#Option A #library(funtimes)
notrend_test(data$LSWI)
notrend_test(data$LSWI,test='MK') # Usa esta función
#notrend_test(data$LSWI,test='WAVK', factor.length = "adaptive.selection")
plot(data$Year,data$LSWI, type='l') # Pinta siempre los resultados
# apply LM to check
summary(lm(data$LSWI~data$Year))
colnames(results_df)
results_df[1,]
#Option B# Sólo quería probar otra forma pero da el mismo resultado #library(Kendall)
MannKendall(data$LSWI)
?write.table
write.table((results_df, file ="Mann-Kendall_lm_lswi_results.txt", append=TRUE, sep="\t", row.names = T, col.names=T)
write.table(results_df, file ="Mann-Kendall_lm_lswi_results.txt", append=TRUE, sep="\t", row.names = T, col.names=T)
getwd()
setwd("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/R")
write.table(results_df, file ="Mann-Kendall_lm_lswi_results.csv", append=TRUE, sep="\t", row.names = T, col.names=T)
write.table(results_df, file ="Mann-Kendall_lm_lswi_results.csv", append=TRUE, sep="\t", row.names = F, col.names=F)
write.table(results_df, file ="Mann-Kendall_lm_lswi_results.csv", append=TRUE, sep="\t", row.names = F, col.names=F)
#library
library(funtimes)
library(Kendall)
# Data
data<-read.delim("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/zones_buffer/lswi_zone01b.csv", sep=",", dec = ".")
#GRÁFICO LSWI HUMEDALES ########################################################
library(ggplot2)
# Tendencia del LSWI en el tiempo separado por humedal
ggplot(datos, aes(x = year, y = lswi, color = wetland_name)) +
geom_line() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Tendencia del LSWI en el tiempo por Humedal",
x = "Año", y = "LSWI") +
facet_wrap(~ wetland_name, scales = "free_y") +
theme_minimal()
# GRÁFICO CON R^2 AJUSTADO #####################################################
library(ggplot2)
library(dplyr)
library(readxl)
datos <-read_excel("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Google Earth Engine/LSWI_zones_hum_buf.xlsx")
# Calcular el R^2 ajustado para cada humedal y unir con los datos originales
datos_con_r2 <- datos %>%
group_by(wetland_name) %>%
do(modelo = lm(lswi ~ year, data = .)) %>%
mutate(adj_r2 = summary(modelo)$adj.r.squared) %>%
ungroup() %>%
left_join(datos, by = "wetland_name")
# Gráfico con R^2 ajustado
ggplot(datos_con_r2, aes(x = year, y = lswi, color = wetland_name)) +
geom_line() +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "Tendencia del LSWI en el tiempo por Humedal",
x = "Año", y = "LSWI") +
facet_wrap(~ wetland_name, scales = "free_y") +
theme_minimal() +
geom_text(data = datos_con_r2 %>% distinct(wetland_name, adj_r2),
aes(x = Inf, y = Inf, label = paste("R² adj: ", round(adj_r2, 3))),
hjust = 1.1, vjust = 1.1, inherit.aes = FALSE, size = 3)
# GRAFICO CON LINEAS DE BUFFER Y DE HUMEDAL SEPARADAS
datos$wetland_or_buffer = recode(datos$wetland_or_buffer,
"wetland" = "Humedal",
"buffer" = "Buffer")
datos_con_r2 <- datos %>%
group_by(wetland_name, wetland_or_buffer) %>%
summarise(adj_r2 = summary(lm(lswi ~ year, data = .))$adj.r.squared) %>%
ungroup()
nombre_humedales_correctos <- c(
"albufera_honda" = "Albufera Honda",
"albufera_nueva" = "Albufera Nueva",
"barranco_del_agua" = "Barranco del Agua",
"canada_de_las_norias" = "Cañada de las Norias",
"cola_del_embalse_del_negratin" = "Cola del embalse del Negratín",
"charcones_de_punta_entinas" = "Charcones de Punta-Entinas",
"humedales_de_baza" = "Humedales de Baza",
"laguna_de_la_gravera" = "Laguna de la Gravera",
"rambla_morales" =  "Rambla Morales",
"ribera_de_la_algaida" = "Ribera de la Algaida",
"rio_antas" = "Río Antas",
"salinas_de_cabo_de_gata" = "Salinas de Cabo de Gata",
"salar_de_los_canos" = "Salar de los Canos",
"salinas_de_cerrillos" = "Salinas de Cerrillos",
"saladar_del_margen" = "Saladar del Margen")
# Crear el gráfico con líneas separadas por "wetland_or_buffer"
ggplot(datos, aes(x = year, y = lswi, color = wetland_or_buffer)) +
geom_line() +
geom_smooth(method = "lm", se = FALSE) +
scale_color_manual(values = c("Humedal" = "blue", "Buffer" = "orange")) +
labs(title = "Tendencia del índice LSWI en el tiempo por humedal",
x = "Año", y = "LSWI", color = "Tipo de área") +
facet_wrap(~ wetland_name, scales = "free_y", labeller = labeller(wetland_name = nombre_humedales_correctos)
) +
coord_cartesian(ylim = c(-0.05, 0.12)) +
theme_minimal() +
geom_hline(yintercept = 0, color = "black", linetype = 2) +
theme(plot.title = element_text(hjust=0.5))
eom_text(data = datos_con_r2,
# Cargar las librerías
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
# Leer los archivos
datos <-read_excel("C:/Users/VE-UGR-0208/Desktop/TFM/rTFM/Resultados_puntos_analisis.xlsx", range = "A1:O2081")
View(datos)
################################################################################
# Análisis exploratorio de los datos: gráficas #################################
pie(table(datos$COMPARACION))
pie(table(datos$MUCVA__USO)) #Usos 1984
pie(table(datos$SIOSE__USO)) #Usos 2023
################################################################################
# Análisis exploratorio de los datos: gráficas #################################
pie(table(datos$COMPARACION))
pie(table(datos$MUCVA__USO)) #Usos 1984
# Contar las frecuencias de cada clase de uso del suelo por humedal
tabla_frecuencia <- table(datos$NOMBRE_HUM, datos$MUCVA__USO)
# Contar la frecuencia de cada clase por humedal
frecuencia_clase_humedal <- datos %>%
group_by(NOMBRE_HUM, MUCVA__USO) %>%
count()
# Ver los resultados
View(frecuencia_clase_humedal)
################################################################################
# Gráfico de barras apiladas para mostrar la proporción de cada uso del suelo por humedal RELATIVO
ggplot(datos, aes(x = MUCVA__USO, fill = NOMBRE_HUM)) +
geom_bar(position = "fill") +
labs(title = "Proporción de usos del suelo en 1984 por humedal",
x = "Uso del suelo",
y = "Proporción") +
scale_fill_viridis_d(option = "H") + #B o H están bien, se distinguen los humedales
theme_minimal() +
theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 0))
ggplot(datos, aes(x = SIOSE__USO, fill = NOMBRE_HUM)) +
geom_bar(position = "fill") +
labs(title = "Proporción de usos del suelo en la actualidad por humedal",
x = "Uso del suelo",
y = "Proporción") +
scale_fill_viridis_d(option = "H") + #B o H están bien, se distinguen los humedales
theme_minimal() +
theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=0))
# ABSOLUTO #####################################################################
ggplot(datos, aes(x = MUCVA__USO, fill = NOMBRE_HUM)) +
geom_bar(position = "stack") +  # Cambia "fill" por "stack" para contar valores absolutos
labs(title = "Número de hectáreas por uso del suelo en 1984 por humedal",
x = "Uso del suelo",
y = "Hectáreas") +
scale_fill_viridis_d(option = "H") + #B o H están bien, se distinguen los humedales
ylim(0, 800) +  # Establece el límite del eje y entre 0 y 800
theme_minimal() +
theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 0))
ggplot(datos, aes(x = SIOSE__USO, fill = NOMBRE_HUM)) +
geom_bar(position = "stack") +  # Cambia "fill" por "stack" para contar valores absolutos
labs(title = "Número de hectáreas por uso del suelo en la actualidad por humedal",
x = "Uso del suelo",
y = "Hectáreas") +
scale_fill_viridis_d(option = "H") + #B o H están bien, se distinguen los humedales
ylim(0, 800) +  # Establece el límite del eje y entre 0 y 800
theme_minimal() +
theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=0))
result_area84 <- df_area_usos84 %>%
group_by(df_area_usos84$`_USOS_DEFI`) %>%
summarise(Total_Area = sum(AREA_POLIG))
result_area20 <- df_area_usos20 %>%
group_by(`_USOS_DEFI`) %>%
summarise(Total_Area = sum(AREA_POLIG))
################################################################################
################################################################################
# Agrupar por ZONA (BUFFER VS HUMEDAL) y COMPARACION (IGUAL VS DISTINTO), y contar las ocurrencias
comparacion_resumen <- datos %>%
group_by(ZONA, COMPARACION) %>%
summarize(count = n()) %>%
ungroup()
print(comparacion_resumen)
# Calcular proporciones
comparacion_proporciones <- comparacion_resumen %>%
group_by(ZONA) %>%
mutate(proporcion = count / sum(count))
print(comparacion_proporciones)
# Gráfico de barras apiladas
ggplot(comparacion_proporciones, aes(x = ZONA, y = proporcion, fill = COMPARACION)) +
geom_bar(stat = "identity") +
labs(title = "Comparación de Cambios de Uso del Suelo Dentro y Fuera de Humedales",
x = "Zona (Dentro/Fuera del Humedal)", y = "Proporción") +
scale_y_continuous(labels = scales::percent_format()) +
theme_minimal()
################################################################################
# Para evaluar los cambios específicos de uso del suelo ########################
# Crear una columna que muestre el cambio de uso del suelo
data <- datos %>%
mutate(cambio_uso = paste(MUCVA__USO, "a", SIOSE__USO))
# Ver los primeros registros para confirmar
head(data)
# Agrupar por zona y tipo de cambio de uso del suelo, y contar las ocurrencias
cambio_uso_buf_hum <- data %>%
group_by(ZONA, cambio_uso) %>%
summarize(count = n()) %>%
ungroup()
# Ver los resultados
print(cambio_uso_buf_hum)
# Gráfico de barras apiladas por tipo de cambio
ggplot(cambio_uso_buf_hum, aes(x = ZONA, y = count, fill = cambio_uso)) +
geom_bar(stat = "identity") +
labs(title = "Cambios de Uso del Suelo Dentro y Fuera de Humedales",
x = "Zona (Dentro/Fuera del Humedal)", y = "Número de Cambios") +
theme_minimal()
# Gráfico de barras agrupadas
ggplot(cambio_uso_buf_hum, aes(x = cambio_uso, y = count, fill = ZONA)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Cambios Específicos de Uso del Suelo por Zona",
x = "Cambio de Uso del Suelo", y = "Número de Cambios") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
################################################################################
# Análisis exploratorio de los datos: gráficas #################################
pie(table(datos$COMPARACION))
pie(table(datos$MUCVA__USO)) #Usos 1984
pie(table(datos$SIOSE__USO)) #Usos 2023
# Contar las frecuencias de cada clase de uso del suelo por humedal
tabla_frecuencia <- table(datos$NOMBRE_HUM, datos$MUCVA__USO)
